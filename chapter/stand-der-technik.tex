\chapter{Stand der Othello-Algorithmen}
\label{cha:stand-der-technik}

% Um das antagonistische Ziel von Othello zu erreichen, versucht jeder Spieler immer den für sich bestmöglichen Spielzug durchzuführen. Da ein einzelner Spielzug kurzfristig belohnend sein kann, da viele gegnerische Steine überflügelt werden, jedoch in einem direkt oder erst später darauffolgenden Zug des Gegenspielers zu Nachteilen führen kann, sollte die Spielweise nicht darauf basieren, mit jedem Zug die maximale Anzahl an Steinen zu überflügeln. Vielmehr muss das Spiel langfristig geplant sein und sich bereits über zukünftige Züge Gedanken gemacht werden. Dies passiert als menschlicher Spieler unterbewusst, jedoch muss ein Roboter hierfür das Prinzip der Suchalgorithmen aus der Informatik anwenden. Diese Suchalgorithmen dienen dazu, einen systematischen Lösungsweg in einem Zustandsraum zu finden. Dieser Zustandsraum setzt sich so aus verschiedenen Zuständen und Übergängen zwischen diesen zusammen. Da der Gegenspieler in Othello mehr oder weniger unvorhersehbare Züge vornimmt, muss bei einem optimalen Suchalgorithmus anhand des aktuellen Spielfortschritts durch den Zustandsraum iteriert werden. Ein Ziel dieser Suchalgorithmen ist es, unnötige Rechnungen zu vermeiden, um den Suchaufwand zu reduzieren oder den kostengünstigsten Lösungsweg zu ermitteln, um an das gewünschte Ziel zu kommen. In diesem Fall ist das gewünschte Ziel, die Partie zu gewinnen, indem man mehr Steine der eigenen Farbe auf dem Spielfeld hat.

Um das antagonistische Zielspiel Othello zu modellieren, strebt jeder Spieler an, in jedem Zug eine Entscheidung zu treffen, die seine Gewinnchancen maximiert. Kurzfristig kann das Überflügeln vieler gegnerischer Steine durch einen einzelnen Zug vorteilhaft erscheinen, jedoch können solche lokalen Maximierungsstrategien in unmittelbar folgenden oder späteren Zügen des Gegenspielers zu Nachteilen führen. Daher sollte die Strategie nicht ausschließlich darauf ausgerichtet sein, in jedem Zug die maximale Anzahl an Steinen zu erfassen, sondern vielmehr langfristig ausgerichtet sein und die Folgen zukünftiger Züge mit in Betracht zu ziehen. Während menschliche Spieler solche Überlegungen häufig intuitiv durchführen, erfordert ein Computergesteuerter Roboter die Anwendung von Suchverfahren aus der Informatik. Diese Suchalgorithmen dienen dazu, in einem Zustandsraum, bestehend aus möglichen Spielpositionen und den Übergängen zwischen ihnen, eine Sequenz von Zügen zu identifizieren, die zur Erreichung eines definierten Ziels führt. Da der Gegenspieler in Othello potenziell unvorhersehbare Züge ausführt, iterieren Suchalgorithmen über den Zustandsraum unter Berücksichtigung möglicher gegnerischer Antworten. Ein zentrales Ziel dieser Verfahren ist es, den Rechenaufwand zu minimieren, indem wenig vielversprechende Suchpfade eliminiert werden, und gleichzeitig den kosteneffizientesten Weg zur Zielerreichung zu ermitteln. In diesem Kontext besteht das Ziel darin, die Partie zu gewinnen, indem am Ende des Spiels eine größere Anzahl eigener Steine auf dem Spielfeld vorhanden ist. \autocite[Kap.~5.1]{russellArtificialIntelligenceModern2016}

Als Vergleichsobjekt zwischen verschiedenen Suchalgorithmen wird zwischen Suchstrategien, Leistungsmessgrößen oder auch subjektiven Vergleichskriterien unterschieden. Die Algorithmen können für die Suchstrategie als uninformiert (Blind) und informiert (Heuristisch) unterschieden werden. Die uninformierte Suche beschränkt sich hierbei auf eine Durchsuchung in der Breite, beispielsweise aller möglichen Spielzüge zu einem bestimmten Spielstand, oder in der Tiefe, durch das Verfolgen eines bestimmten Ablaufs an Zügen. Die informierte Suche nutzt dagegen Heuristiken, um den zu durchsuchenden Zustandsraum zu reduzieren. Dies ist in dieser Arbeit geeigneter, da es sich bei Othello um ein komplexes Spiel im Sinne der Spielkomplexität handelt und der nicht der gesamte Zustandsraum mit allen möglichen Lösungswegen modelliert werden kann \autocite[Kap.~3]{russellArtificialIntelligenceModern2016}.

Heuristiken sind Regeln oder Strategien, um Entscheidungen zu treffen oder Probleme zu lösen, ohne alle verfügbaren Informationen zu analysieren. Dies wird eingesetzt, da systematische Fehler in Kauf genommen werden, um den nötigen Aufwand zu verringern. In der Informatik werden dafür heuristische Funktionen genutzt, um unwirtschaftliche Teile des Zustandssuchraums zu vernachlässigen und vielversprechendere Lösungswege zu bevorzugen \autocite{toddSimpleHeuristicsThat1999}.

Leistungsmessgrößen geben den Suchalgorithmen konkrete Bewertungen anhand ihres Speicherbedarfs, in Form von den benötigten Bytes, ihrer jeweiligen Zeitkomplexität anhand von Landau-Symbolen (englisch big O notation) und durch die Güte der Heuristik anhand von Gütefunktionen, wie effektiv der Suchalgorithmus den Zustandssuchraum einschränkt, indem sie die Zustände bewerten \autocite[Kap.~5.2]{russellArtificialIntelligenceModern2016}.

In der Informatik werden die Landau Symbole benutzt, um Algorithmen anhand des Wachstums ihres Zeitbedarfs in Abhängigkeit des Wachstums der Eingangsgrößen zu klassifizieren. Dabei werden zwei Funktionen $f(n)$ als zu bestimmende Funktion und $g(n)$ als Vergleichsfunktion angenommen. Der Zusammenhang wird dann als $f(n) \in O(g(n))$ dargestellt und sagt aus, dass die Funktion $f$ höchstens genauso schnell wie $g$ wächst. Konstanten werden dabei in der Regel vernachlässigt, da sie das Wachstumsverhalten nicht verändern \autocite[Kap.~3]{bachmannAnalytischeZahlentheorieDargestellt1894}.

Als Beispiel wird ein Feld mit $n$ Elementen angenommen, in dem ein bestimmter Wert $x$ gesucht wird, der sich an einer zufälligen Stelle befindet. Das Feld wird linear durchsucht, indem jedes Element nacheinander überprüft wird. Daraus ergeben sich verschiedene Laufzeiten, je nachdem, an welcher Stelle sich $x$ befindet:

\begin{itemize}
	\item \textbf{Bester Fall:} $x$ steht an erster Stelle, $T(n) = 1$
	\item \textbf{Schlechtester Fall:} $x$ steht an letzter Stelle oder ist nicht enthalten, $T(n) = n$
	\item \textbf{Durchschnitt:} $x$ steht im Mittel in der Mitte, $T(n) = \frac{n}{2}$
\end{itemize}

Für die Landau Symbole ergibt sich dadurch $T(n) \in O(n)$. Das bedeutet in diesem Fall, dass die Laufzeit der linearen Suche proportional zu der Anzahl der Elemente im Feld wächst.

Gütefunktionen bewerten Zustände innerhalb eines Suchalgorithmus anhand von numerischen Werten. Dabei wird im Falle von Othello bewertet, wie gut ein Zustand im Hinblick auf einen Sieg ist, wonach sich die nächsten zu untersuchenden Zustände richten. So wird der Zustandsraum gezielt zu durchsuchen, anstatt alle Möglichkeiten blind zu prüfen, wodurch womöglich Rechenressourcen verschwendet werden. Dabei wird zwischen Kostenfunktionen, die den bisherigen Aufwand messen, heuristischen Funktionen, die den verbleibenden Aufwand zum Ziel schätzen und der kombinierten Gütefunktion, die die beiden anderen Funktionen kombiniert, unterschieden.

Als Beispiel wird die Zustandsbewertung bei einer Zahlensuche verwendet. Ziel ist es von einer Startzahl $s$ zu einer Zielzahl $z$ zu kommen. Übergänge sind dabei die Erhöhung oder Verringerung der aktuellen Zahl um den Wert 1 und den Kosten von jedem Übergang von ebenfalls 1. Ein Zustand wird in Form einer Ganzzahl $n$ dargestellt. Die Kostenfunktion $g(n) = |n - s|$ beschreibt die bisher ausgeführten Schritte. Die heuristische Funktion wird $h(n) = |n - z|$, als Differenz der aktuellen Zahl bis zur Zielzahl angenommen. Die kombinierte Gütefunktion ist somit $f(n) = g(n) + h(n) = |n - s| + |n - z|$. Angenommen die Startzahl sei $s = 10$ und die Zielzahl $z = 20$. Es kann nun für jeden Zustand $n$ die Güte berechnet werden.

\begin{table}[hbt]
	\centering
	\captionabove[Gütefunktion für Zustände]{Gütefunktion $f(n) = |n - 10| + |n - 20|$ für die Zustände $n = 8 \dots 20$.}
	\label{tab:guetefunktion}
	
	\renewcommand{\arraystretch}{1.5}
	\setlength{\tabcolsep}{6pt}
	
	\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
		Zustand $n$ & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & 21 \\ \hline
		$f(n)$ & 14 & 12 & 10 & 10 & 10 & 10 & 10 & 10 & 10 & 10 & 10 & 10 & 10 & 12\\
	\end{tabular}
\end{table}

Die Zahlensuche wird beendet sobald $n = z$, wodurch Zustand $n = 21$ nicht erreichbar wäre, jedoch zur Veranschaulichung trotzdem dargestellt ist. Der Suchalgorithmus geht nun immer in den Zustand $n$ über, der das kleinste $f(n)$ besitzt bei dem $n$ näher an $z$ liegt, als im aktuellen Zustand. Um eine Vergleichbarkeit zwischen Suchalgorithmen herzustellen, müssen alle betrachteten Algorithmen dasselbe Problem behandeln, sowie denselben Zustandsraum und dieselbe Gütefunktion verwenden.

Des weiteren können subjektiven Vergleichskriterien dabei die Anwendbarkeit auf den jeweiligen Zweck oder die Robustheit unter Zeit bzw. Ressourcenbegrenzung sein \autocite{balogunComparativeAnalysisAIbased2024}.

\section{Geeignete Algorithmen für Othello unter begrenzten Ressourcen}
\label{sec:geeignete-algorithmen}

Um die Algorithmen zu vergleichen müssen vorerst Rahmenbedingungen zu Bewertung und Messung der Bewertungsgrößen definiert werden. Es werden drei Aufstellungen des Spielfeldes festgelegt, anhand denen jeder Algorithmus den nächstbesten Zug bestimmt. Die Aufstellungen basieren auf manuell gespielten Partien bis zu einem gewissen Punkt, um einen realistischen Spielstand widerzuspiegeln. Es handelt sich dabei um eine Startstellung, bei der 14 Steine auf dem Spielfeld gelegt sind, eine Stellung etwa in der Mitte des Spiels mit 40 Steinen und eine am Ende der Partie mit 52 Steinen. In Jeder Aufstellung ist der Spieler mit den schwarzen Steinen am Zug, jedoch spielt es keine Rolle, welche Farbe von den Algorithmen behandelt wird und wer begonnen hat.

\begin{figure}[!h]
	\centering
	\input{tikz/reversi-board}
	\subfigure[Spielsituation am Anfang]{
		\begin{tikzpicture}[scale=0.5]
			\rvBoard
			\rvCoords
			\rvStonesBlack{B2, C2, C3, C6, D2, D4}
			\rvStonesWhite{C4, C5, D3, D5, E3, E4, E5, E6}
			\rvMovesBlack{B4, B6, D6, F2, F3, F4, F5, F6}
		\end{tikzpicture}
	}
	\subfigure[Spielsituation in der Mitte]{
		\begin{tikzpicture}[scale=0.5]
			\rvBoard
			\rvCoords
			\rvStonesBlack{A6, A7, A8, B4, B7, C1, C5, C7, D4, D6, E1, F5, G1, H6}
			\rvStonesWhite{B5, B6, C2, C6, D1, D2, D3, D5, D7, E2, E3, E4, E5, E6, E7, E8, F2, F3, F6, F7, G2, G5, G6, G7, H2, H5}
			\rvMovesBlack{A5, B1, C3, C4, C8, D8, F4, F8, G3, H1, H4, H7, H8}
		\end{tikzpicture}
	}
	\subfigure[Spielsituation an Ende]{
		\begin{tikzpicture}[scale=0.5]
			\rvBoard
			\rvCoords
			\rvStonesBlack{A4, A5, A6, B4, B5, B6, C3, C4, C5, C6, D1, D8, E2, E3, E5, F1, F3, F5, F8, G1, G2, G4, G5, H1, H3, H5}
			\rvStonesWhite{A3, A7, B3, B7, C1, C2, C7, C8, D2, D3, D4, D5, D6, D7, E4, E6, E7, F2, F4, F6, F7, G3, G6, G7, H6, H8}
			\rvMovesBlack{A2, A8, B1, B2, B8, E1, D8, G8, H2, H7}
		\end{tikzpicture}
	}
	\caption[Spielsituationen Algorithmen]{Spielsituation in drei Fortschritten unterschiedlicher Partien.}
	\label{fig:startaufstellungen}
\end{figure}

Des weiteren spielt die Gütefunktion und die Gewichtung der Faktoren eine tragende Rolle, für welchen Spielzug sich die Algorithmen entscheiden. Um die Gütefunktion aufzustellen wird der Disk-Square-Ansatz angewandt. nach diesem wird eine Matrix aufgestellt, in der alle Positionen des Spielfeldes mit einer Gewichtung behaftet sind. Dabei sind Positionen in den Ecken, sowie an den Kanten, jedoch nicht an den direkt anliegenden Feldern an den Kanten neben den Ecken, besonders erstrebenswert, da diese gar nicht oder schwerer zurückgewonnen werden können, als in der Mitte des Feldes. Daraus ergibt sich, dass die Felder, die direkt neben den Kanten liegen nicht vorteilhaft sind, da sie dem Gegenspieler ermöglichen die Kanten zu erreichen \autocite[Kap.~2.A]{setthawongUsingGeneticApproach2005}. Die gewählte Gewichtungsmatrix sieht wie folgt aus:

\begin{figure}[!h]
	\centering
	\input{tikz/reversi-board}
	\begin{tikzpicture}[scale=0.75]
		\rvBoard
		\rvCoords
		\rvValueMatrix
		{120,-20,20,5,5,20,-20,120}
		{-20,-40,-5,-5,-5,-5,-40,-20}
		{20,-5,15,3,3,15,-5,20}
		{5,-5,3,3,3,3,-5,5}
		{5,-5,3,3,3,3,-5,5}
		{20,-5,15,3,3,15,-5,20}
		{-20,-40,-5,-5,-5,-5,-40,-20}
		{120,-20,20,5,5,20,-20,120}
	\end{tikzpicture}
	\caption[Gewichtungsmatrix]{Die Gewichtungsmatrix auf dem Spielbrett dargestellt.}
	\label{fig:gewichtungsmatrix}
\end{figure}

\newpage
Zusätzlich zu der Gewichtungsmatrix wird die Mobilität des Spielers im Vergleich zum Gegner in Betracht gezogen. Dazu werden die eigenen möglichen Züge mit den möglichen Zügen des Gegners verglichen, wäre dieser stattdessen am Zuge. Eine höhere Mobilität ist Erstrebenswert, da somit mehr Möglichkeiten für den Spielverlauf entstehen \autocite[Kap.~3.A]{setthawongUsingGeneticApproach2005}. Die Mobilität errechnet sich mit $M = n_{Zuege\_B} - n_{Zuege\_W}$. Durch eine Gewichtung der Mobilität $\omega_M$ ergibt sich zusammen mit der Gewichtungsmatrix die Gütefunktion: 
\begin{equation}
	f(n) = Gesamtpunktzahl_B - Gesamtpunktzahl_W + M * \omega_M
\end{equation}

Da die Algorithmen sich hauptsächlich darin unterscheiden, wie effizient sie den Zustandssuchraum reduzieren muss die Suchtiefe untersucht werden. Hierzu werden alle Situationen von den Algorithmen mit Suchtiefen von 1 bis 5 berechnet. Bei der Suchtiefe sind somit die Landau Symbole zu beachten, da der Zustandsraum nicht linear mit der Anzahl der Suchtiefe und unterschiedlich zwischen den Algorithmen wächst. Dies bedeutet, dass der Rechenaufwand signifikant mit jeder Erhöhung der Suchtiefe wächst und man einen gewissen Punkt erreicht, an dem eine größere Suchtiefe keine Vorteile mehr erzeugt, da die Varianz der Züge des Gegners zu groß wird.

Bewertet werden die Algorithmen anhand ihres Zeitbedarfs, Speicherbedarfs, ihrer Güte und ihrer Robustheit. Der Zeitbedarf wird hierzu in Mikrosekunden und der Speicherbedarf wird in Bytes gemessen. Um die Robustheit zu bestimmen, wird die Basisgewichtungsmatrix mithilfe von Zufallszahlen variiert. Dazu wird ein sogenannter Seed Key verwendet. Dieser Seed Key initialisiert den deterministischen Zufallszahlengenerator, um dieselbe Folge an Pseudozufallszahlen zu erhalten. So kann gewährleistet werden, dass die Algorithmen bei mehreren Durchläufen dieselben Rahmenbedingungen haben. Auf welchen Wert der Seed Key gesetzt wird spielt in erster Linie keine Rolle, relevant ist nur, dass er in allen Durchläufen gleich ist. Um Die Gewichtungsmatrix anzupassen wird darauf für jedes Element der Matrix eine Pseudozufallszahl $r$ zwischen $-0.5$ und $0.5$ generiert. Jedes Element $i_{m, n}$ wird dann mit $1 + r$ multipliziert. Von diesen Pseudozufallszahlen werden drei Sets generiert. Zusätzlich wird die Gewichtung der Mobilität mit den Werten 0.75, 1.00 und 1.25 multipliziert. Um viele Varianten zu gewährleisten werden alle Kombinationen der betrachtet und jede Kombination 5 mal berechnet, um einen Stichprobenumfang von $3\ Zufallszahlensets * 3\ Mobilitätsgewichtungen * 5\ Durchl\textit{ä}ufe = 45\ Stichproben$ zu erhalten. Jeder Algorithmus berechnet darauf den besten Zug für die Suchtiefen 1, 2, 3, 4 und 5. Für die 5 betrachteten Algorithmen ergibt sich somit ein gesamter Berechungssatz von $45\ Stichproben * 5\ Suchtiefen * 5\ Algorithmen = 1125\ Berechnungss\textit{ä}tzen$.

Die Berechnungen werden mithilfe von Python Skripten durchgeführt, da die vorgesehene Hardware für den Roboter ebenfalls Python verwendet. Als Entwicklungsumgebung wurde Visual Studio Code, aufgrund der Vertrautheit mit dieser, verwendet. Der Computer der für die Berechnungen verwendet wurde besitzt abweichende Hardware von der des Roboter wodurch auch die Berechnungszeiten beeinflusst werden, jedoch ist die Vergleichbarkeit der Algorithmen trotz dessen gewährleistet. Die Skripte geben eine Datei im .txt Format aus und sind in Anhang enthalten.

\paragraph{Minimax-Algorithmus}
\label{subsec:minimax-algorithmus}
Der Minimax-Algorithmus kann als Übergeordnet angesehen werden, auf dem andere Algorithmen aufbauen und diesen optimieren. Bei diesem Algorithmus wird von zwei Spielern ausgegangen: der Max-Spieler, der versucht, den eigenen Wert unter den möglichen Optionen zu maximieren, und der Min-Spieler, der versucht, den minimalen Wert für den Max-Spieler zu erreichen. Der Min-Spieler ist somit der Gegenspieler. Als Beispiel kann folgender Spielbaum konstruiert werden:

\begin{figure}[H]
	\centering
	
	\forestset{
		Knotenlabel/.style={
			label/.append style={font=\normalsize\bfseries}
		},
		EL/.style n args={1}{
			edge label={
				node[midway, above, sloped,
				fill=white,
				inner sep=1.8pt,
				font=\normalsize\normalfont]{#1}
			}
		}
	}
	
	\begin{forest}
		for tree={
			grow'=south,
			edge={-latex, line width=1pt},
			parent anchor=south,
			child anchor=north,
			s sep=12mm,
			l sep=24mm,
			draw=none,
			circle,
			fill,
			inner sep=2pt,
			label distance=2.5mm,
			Knotenlabel,
		}
		[ , label=above:{[Max]}
		[ , label=right:{(b)[Min]}
		[ , EL={9} ]
		[ , EL={2} ]
		]
		[ , label=right:{(a)[Min]}
		[ , EL={5} ]
		[ , EL={3} 
		]
		]
		]
	\end{forest}
	
	\vspace{0.5\baselineskip}
	\caption[Beispielbaum Minimax]{Beispielbaum des Minimax-Algorithmus.}
	\label{fig:minimax-baum}
\end{figure}

Nun wird an jedem Min-Knoten davon ausgegangen, dass immer der geringste Wert gewählt wird. In diesem Fall gilt für den linken Knoten (a) $min(3, 5) = 3$ und für den rechten Knoten (b) $min(2, 9) = 2$. Für den Max-Spieler bleiben somit die Knoten 2 an Stelle (b) und 3 an Stelle (a) übrig. Der Algorithmus entscheidet sich folglich für den linken Pfad, da $max(3, 2) = 3$. In Othello kann für die Zahlenwerte die Heuristik verwendet werden, die jeden Zustand bewertet.

Die exakten Zahlenwerte der Ergebnisse, die auf den folgenden Seiten in Diagrammen dargestellt sind, sind in den Tabellen \ref{tab:all-times-grouped} für die Laufzeiten und \ref{tab:all-memory-grouped} für den Speicherbedarf nachzulesen.

\newpage
\paragraph{Alpha-Beta-Pruning}
\label{subsec:alpha-beta-pruning}
 ist eine Optimierung des Minimax‑Algorithmu. Der Algorithmus verwaltet zwei Schranken $\alpha$ und $\beta$, welche die beste bisher gefundene Bewertung für den Max‑ bzw. Min‑Spieler repräsentieren. Diese beiden Schranken bestimmen nun, welcher Pfad nicht weiterverfolgt werden muss. Anhand des Beispiels \ref{fig:minimax-baum} sind die Startwerte $\alpha = -\inf$ und $\beta = \inf$. Zuerst wird am linken Min-Knoten geprüft auf $min(\inf, 3) = 3 = \beta$ und darauf $min(3, 5) = 3 = \beta$. Am oberen Max-Knoten wird $max(-\inf, 3) = 3 = \alpha$ bestimmt. Für den rechten Ast wird dasselbe Verfahren durchgeführt, wodurch sich $\beta = 2$ ergibt. Anhand der Abbruchbedingung $\alpha \geq \beta$ kann nun bestimmt werden, dass die Suche im rechten Ast abgebrochen werden kann, falls dieser weiterführen würde. So kann die Anzahl der auszuwertenden Zustände erheblich reduziert werden \autocite[Kap.~5.3]{russellArtificialIntelligenceModern2016}.

\begin{figure}[H]
	\centering
	\subfigure[Durchschnittliche Zeit pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Zeit (µs)},
				ymode=log, xtick={1,...,5},
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={AlphaBeta: Durchschnittliche Zeit}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,2179) (2,8412) (3,62315) (4,310785) (5,2111972)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,2975) (2,10354) (3,117572) (4,425988) (5,4989373)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,1949) (2,5047) (3,32526) (4,78932) (5,338372)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\hfill
	\subfigure[Speicherverbrauch pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Speicher (Bytes)},
				xtick={1,...,5},
				scaled y ticks=false,
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={AlphaBeta: Speicherverbrauch}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,5609) (2,8443) (3,9585) (4,11389) (5,13701)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,5336) (2,6961) (3,9550) (4,11502) (5,13468)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,5304) (2,6913) (3,9336) (4,11251) (5,13030)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\caption[AlphaBeta Performance]{Durchschnittliche Zeit und Speicherverbrauch des Alpha-Beta-Pruning in Abhängigkeit von der Suchtiefe.}
	\label{fig:alphabeta-performance}
\end{figure}

Dieser erste Algorithmus setzt eine Grundlinie, an der sich bei den anderen Algorithmen orientiert werden kann, da er die einfache Verbesserung des Minimax-Algorithmus in dieser Untersuchung ist. Bereits hier ist das exponentielle Wachstum des Zeitbedarfs, sowie das lineare Wachstum des Speicherbrauchs festzustellen.

\newpage
\paragraph{Iterative Deepening}
\label{subsec:iterative-deepening}
verwendet den implementierten Alpha-Beta-Algorithmus mit, jedoch sucht er nicht von Anfang an in einer festen Tiefe. Hingegen startet er bei einer Tiefe von 1 und erhöht die Suchtiefe mit jedem Durchlauf. So wird immer der aktuell beste Zug berechnet, ohne auf die gesamte Berechnung der höchsten Tiefe warten zu müssen. Dies ermöglicht es, theoretisch schon früher abzubrechen, falls ab einer gewissen Tiefe kein anderes Ergebnis errechnet wird. Die Anwendung ist stark von der tatsächlich benötigten Tiefe abhängig und ob diese im Laufe des Spiels variiert, wodurch Ressourcen je nach Situation eingespart werden könnten. In dieser Anwendung wird jede Tiefe bis zur Zieltiefe ohne Abbruchbedingung durchgerechnet \autocite[Kap.~3.5]{russellArtificialIntelligenceModern2016}.  

\begin{figure}[H]
	\centering
	\subfigure[Durchschnittliche Zeit pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Zeit (µs)},
				ymode=log, xtick={1,...,5},
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={IterDeep: Durchschnittliche Zeit}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,2279) (2,10617) (3,74994) (4,390209) (5,2521484)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,2965) (2,13457) (3,132964) (4,567151) (5,5639908)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,2105) (2,7221) (3,39634) (4,118971) (5,463935)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\hfill
	\subfigure[Speicherverbrauch pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Speicher (Bytes)},
				xtick={1,...,5},
				scaled y ticks=false,
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={IterDeep: Speicherverbrauch}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,5840) (2,8091) (3,10909) (4,12820) (5,15078)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,6448) (2,8803) (3,10998) (4,12894) (5,14850)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,6080) (2,8400) (3,10803) (4,12718) (5,14366)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\caption[IterDeep Performance]{Durchschnittliche Zeit und Speicherverbrauch des IterDeep-Algorithmus in Abhängigkeit von der Suchtiefe.}
	\label{fig:iterdeep-performance}
\end{figure}

Es ergibt sich, dass der Iterative Deepening Algorithmus somit für jede Zieltiefe, zusätzlich zur selben Zeit wie das Alpha-Beta-Pruning, die Zeit wie das Alpha-Beta-Pruning für alle vorherigen Suchtiefen benötigt, also $T_{ID}^d=T_{AB}^d+T_{AB}^{d-1}+\dots+T_{AB}^1$. Im Speicherverbrauch gibt es dieses Verhalten nicht, jedoch benötigt Iterative Deepening dennoch mehr Speicher als Alpha-Beta-Pruning allein.

\newpage
\paragraph{Move Ordering}
\label{subsec:move-ordering}
ist ebenfalls eine Abwandlung des Alpha-Beta-Pruning. Bei Alpha-Beta-Pruning spielt die Suchreihenfolge eine essenzielle Rolle im Zeitbedarf. Wenn die besten Züge zuerst geprüft werden können, können auch viele Äste frühzeitig verworfen werden. Dazu sortiert der Algorithmus zuerst die möglichen Züge grob nach ihrer Qualität beziehungsweise im Sinn von Othello nach ihrer heuristischen Bewertung in der ersten Suchtiefe, also den aktuell möglichen Zügen. Daraufhin wird in den folgenden Suchtiefen Alpha-Beta-Pruning angewendet. \autocite[Kap.~5.3.1]{russellArtificialIntelligenceModern2016}.  

\begin{figure}[H]
	\centering
	\subfigure[Durchschnittliche Zeit pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Zeit (µs)},
				ymode=log, xtick={1,...,5},
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={MoveOrder: Durchschnittliche Zeit}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,4436) (2,28899) (3,97354) (4,405391) (5,1178975)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,5568) (2,43298) (3,150109) (4,656074) (5,2292903)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,3543) (2,15955) (3,57021) (4,154632) (5,408477)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\hfill
	\subfigure[Speicherverbrauch pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Speicher (Bytes)},
				xtick={1,...,5},
				scaled y ticks=false,
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={MoveOrder: Speicherverbrauch}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,5632) (2,7337) (3,9136) (4,10673) (5,12712)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,5738) (2,7417) (3,9235) (4,10802) (5,12413)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,5649) (2,7247) (3,9106) (4,10592) (5,12274)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\caption[MoveOrder Performance]{Durchschnittliche Zeit und Speicherverbrauch des MoveOrder-Algorithmus in Abhängigkeit von der Suchtiefe.}
	\label{fig:moveorder-performance}
\end{figure}

Grundsätzlich ist zu erkennen, dass in dieser Untersuchung erst ab einer Suchtiefe von 5 ein Zeitvorteil festgestellt werden kann. Dieser hingegen ist signifikant gegenüber den anderen Algorithmen, da bereits frühzeitig große Teile verworfen werden können, die erst auf höherer Suchtiefe ausgezahlt machen. Im Speicherbrauch jedoch ist bereits bei geringeren Suchtiefen ein Vorteil zu erkennen, auch wenn dieser nicht dasselbe signifikante Ausmaß annimmt.

\newpage
\paragraph{Negamax}
\label{subsec:negamax}
ist, so wie auch Iteration Deepening und Move Ordering, eine Abwandlung des Alpha-Beta-Pruning. Die formale Funktionsweise entspricht der eines Minimax-Algorithmus, jedoch wird hier nicht von einem Max- und Min-Spieler ausgegangen, sondern einem einheitlichen Max-Spieler. Da nun für beide Spieler immer ein maximales Ergebnis erzielt werden möchte, wird das Vorzeichen für die Bewertungsfunktion umgedreht. So bedeutet ein positiver Wert ein Vorteil und ein negativer Wert ein Nachteil. Dies ermöglicht eine simplere Implementierung \autocite{abdelbarAlphaBetaPruningAlthofers2012}.

\begin{figure}[H]
	\centering
	\subfigure[Durchschnittliche Zeit pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Zeit (µs)},
				ymode=log, xtick={1,...,5},
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={Negamax: Durchschnittliche Zeit}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,2207) (2,8354) (3,63469) (4,316436) (5,2124191)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,2873) (2,10285) (3,118282) (4,432783) (5,5011795)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,1936) (2,5070) (3,32142) (4,78696) (5,339006)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\hfill
	\subfigure[Speicherverbrauch pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Speicher (Bytes)},
				xtick={1,...,5},
				scaled y ticks=false,
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={Negamax: Speicherverbrauch}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,5064) (2,6896) (3,9399) (4,11316) (5,13626)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,5336) (2,6961) (3,9551) (4,11502) (5,13454)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,5304) (2,6913) (3,9321) (4,11275) (5,13029)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\caption[Negamax Performance]{Durchschnittliche Zeit und Speicherverbrauch des Negamax-Algorithmus in Abhängigkeit von der Suchtiefe.}
	\label{fig:negamax-performance}
\end{figure}

Dieser Zusammenhang lässt sich an den Messungen erkennen, da die Werte annähernd exakt mit denen des Alpha-Beta-Pruning übereinstimmen. In dieser Implementierung bedeutet dies, dass zwischen diesen beiden Algorithmen nur anhand der persönlichen Präferenz in Form von Kompaktheit des Codes oder der klaren Trennung der beiden Spieler entschieden werden könnte.

\newpage
\paragraph{Negascout}
\label{subsec:negascout}
ist eine Weiterentwicklung von Negamax. Um die Anzahl der zu untersuchenden Knoten weiter zu reduzieren, wir die Annahme getroffen, dass der erste untersuchte Zug der beste ist. Das bedeutet, dass nur der erste Ast in der Liste an Zügen komplett nach dem Verfahren des Negamax untersucht wird. Die anderen Züge in der obersten Ebene werden nur mit einem Nullfenster überprüft, das aussagt, ob einer dieser Züge besser wäre, als der exakte Wert des ersten Asts, jedoch liefert dies noch keinen exakten Wert für den gesamten darauffolgenden Ast. Falls der Zug nicht besser ist, wird der Zug verworfen und die Unterknoten nicht weiter untersucht. Wenn der Zug jedoch besser ist, wird nochmals der komplette Ast auf den genauen Wert geprüft \autocite{plaatBestfirstFixeddepthMinimax1996}.

\begin{figure}[H]
	\centering
	\subfigure[Durchschnittliche Zeit pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Zeit (µs)},
				ymode=log, xtick={1,...,5},
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={Negascout: Durchschnittliche Zeit}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,2362) (2,8919) (3,52686) (4,268206) (5,1235961)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,3010) (2,14207) (3,140836) (4,507567) (5,3910554)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,2196) (2,5838) (3,35259) (4,101064) (5,384424)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\hfill
	\subfigure[Speicherverbrauch pro Tiefe]{
		\begin{tikzpicture}
			\begin{axis}[
				width=0.45\textwidth,
				xlabel={Tiefe}, ylabel={Speicher (Bytes)},
				xtick={1,...,5},
				scaled y ticks=false,
				legend style={at={(0.5,-0.25)}, anchor=north, legend columns=-1, font=\small},
				title={Negascout: Speicherverbrauch}
				]
				\addplot[smooth,mark=o,blue] coordinates {(1,5248) (2,7032) (3,9489) (4,11621) (5,13704)}; \addlegendentry{Anfang}
				\addplot[smooth,mark=square,red] coordinates {(1,5408) (2,7330) (3,9786) (4,11783) (5,13796)}; \addlegendentry{Mitte}
				\addplot[smooth,mark=triangle,green] coordinates {(1,5376) (2,7083) (3,9549) (4,11477) (5,13404)}; \addlegendentry{Ende}
			\end{axis}
		\end{tikzpicture}
	}
	\caption[Negascout Performance]{Durchschnittliche Zeit und Speicherverbrauch des Negascout-Algorithmus in Abhängigkeit von der Suchtiefe.}
	\label{fig:negascout-performance}
\end{figure}

Anhand des Zeitbedarfs ist erkennbar, dass eine Zeitersparnis stark von Spielzustand, und somit der Menge der Verzweigungen, und der Suchtiefe abhängt. Bei niedrigen Suchtiefen wird sogar mehr Zeit benötigt, da der Algorithmus durch die sehr ausführliche Suche am Anfang mehr prüfen muss im Vergleich zu den anderen Algorithmen. Bei größerer Suchtiefe kann zudem auch mehr verworfen werden, wenn einer der oberen Züge schon ein geringeres Ergebnis liefert.

\begin{table}[H]
	\centering
	\small
	\caption{Laufzeiten in $\mu$s pro Suchtiefe für alle Algorithmen}
	\label{tab:all-times-grouped}
	\renewcommand{\arraystretch}{1.3}
	\setlength{\tabcolsep}{4pt}
	\begin{tabular}{c c|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}}
		Algorithmus & Stellung & 1 & 2 & 3 & 4 & 5 \\ \hline
		\multirow{3}{*}{AlphaBeta}
		& Anfang & 2.179 & 8.412 & 62.315 & 310.785 & 2.111.972 \\
		& Mitte  & 2.975 & 10.354 & 117.572 & 425.988 & 4.989.373 \\
		& Ende   & 1.949 & 5.047 & 32.526 & 78.932 & 338.372 \\ \hline
		\multirow{3}{*}{IterDeep}
		& Anfang & 2.279 & 10.617 & 74.994 & 390.209 & 2.521.484 \\
		& Mitte  & 2.965 & 13.457 & 132.964 & 567.151 & 5.639.908 \\
		& Ende   & 2.105 & 7.221 & 39.634 & 118.971 & 463.935 \\ \hline
		\multirow{3}{*}{MoveOrder}
		& Anfang & 4.436 & 28.899 & 97.354 & 405.391 & 1.178.975 \\
		& Mitte  & 5.568 & 43.298 & 150.109 & 656.074 & 2.292.903 \\
		& Ende   & 3.543 & 15.955 & 57.021 & 154.632 & 408.477 \\ \hline
		\multirow{3}{*}{Negamax}
		& Anfang & 2.207 & 8.354 & 63.469 & 316.436 & 2.124.191 \\
		& Mitte  & 2.873 & 10.285 & 118.282 & 432.783 & 5.011.795 \\
		& Ende   & 1.936 & 5.070 & 32.142 & 78.696 & 339.006 \\ \hline
		\multirow{3}{*}{Negascout}
		& Anfang & 2.362 & 8.919 & 52.686 & 268.206 & 1.235.961 \\
		& Mitte  & 3.010 & 14.207 & 140.836 & 507.567 & 3.910.554 \\
		& Ende   & 2.196 & 5.838 & 35.259 & 101.064 & 384.424 \\
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\small
	\caption{Speicherverbrauch in Bytes pro Suchtiefe für alle Algorithmen}
	\label{tab:all-memory-grouped}
	\renewcommand{\arraystretch}{1.3}
	\setlength{\tabcolsep}{4pt}
	\begin{tabular}{c c|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}}
		Algorithmus & Stellung & 1 & 2 & 3 & 4 & 5 \\ \hline
		\multirow{3}{*}{AlphaBeta}
		& Anfang & 5.609 & 8.443 & 9.585 & 11.389 & 13.701 \\
		& Mitte  & 5.336 & 6.961 & 9.550 & 11.502 & 13.468 \\
		& Ende   & 5.304 & 6.913 & 9.336 & 11.251 & 13.030 \\ \hline
		\multirow{3}{*}{IterDeep}
		& Anfang & 5.840 & 8.091 & 10.909 & 12.820 & 15.078 \\
		& Mitte  & 6.448 & 8.803 & 10.998 & 12.894 & 14.850 \\
		& Ende   & 6.080 & 8.400 & 10.803 & 12.718 & 14.366 \\ \hline
		\multirow{3}{*}{MoveOrder}
		& Anfang & 5.632 & 7.337 & 9.136 & 10.673 & 12.712 \\
		& Mitte  & 5.738 & 7.417 & 9.235 & 10.802 & 12.413 \\
		& Ende   & 5.649 & 7.247 & 9.106 & 10.592 & 12.274 \\ \hline
		\multirow{3}{*}{Negamax}
		& Anfang & 5.064 & 6.896 & 9.399 & 11.316 & 13.626 \\
		& Mitte  & 5.336 & 6.961 & 9.551 & 11.502 & 13.454 \\
		& Ende   & 5.304 & 6.913 & 9.321 & 11.275 & 13.029 \\ \hline
		\multirow{3}{*}{Negascout}
		& Anfang & 5.248 & 7.032 & 9.489 & 11.621 & 13.704 \\
		& Mitte  & 5.408 & 7.330 & 9.786 & 11.783 & 13.796 \\
		& Ende   & 5.376 & 7.083 & 9.549 & 11.477 & 13.404 \\
	\end{tabular}
\end{table}

\section{Nicht betrachtete Algorithmen}
\label{sec:nicht-betrachtete-algorithmen}

Abgesehen von den untersuchten Algorithmen, die auf dem simplen Minimax-Algorithmus aufbauen, gibt es weitere fortgeschrittene Algorithmen, die den Rahmen dieser Arbeit überschreiten, aufgrund von Ressourcenbegrenzungen der geplanten Hardware, sowie der Umsetzungskomplexität. Aus Gründen der Vollständigkeit werden diese trotz dessen erwähnt, da diese unter anderen Rahmenbedingungen Nützlichkeit erweisen können.

\paragraph{MTDF}
\label{subsec:mtdf-alpha-beta}

 steht für Memory-enhanced Test Driver und ist eine Variante der Alpha-Beta-Suche, die durch wiederholte, eng begrenzte Suchvorgänge den Zustandsraum durchsucht. Anstatt sofort einen genauen Wert zu berechnen, wird eine Schätzung als Startpunkt genommen, wovon aus die obere und untere Schranke so lange angepasst wird, bis die exakte Bewertung erreicht ist. Der Algorithmus nutzt dafür Transpositionstabellen, um bereits berechnete Knoten zwischenzuspeichern \autocite{plaatBestfirstFixeddepthMinimax1996}. Dafür wird kontinuierlich Speicher benötigt, welcher auf dem verwendeten eingebetteten System nur begrenzt zur Verfügung steht. Wenn nicht alle nötigen Knoten gespeichert werden können wird die Suche ineffizient.

\paragraph{Q-Learning}
\label{subsec:q-learning}
 ist ein lernbasierter Ansatz auf Basis von bestärkendem Lernen. Bei bestärkendem Lernen führt eine künstliche Intelligenz selbstständig Aktionen durch und wird darauf für die Entscheidungen belohnt oder bestraft. Dieser Ansatz basiert auf der heuristischen Methode des Versuch und Irrtum, bei dem so lange Lösungswege getestet werden, bis ein geeigneter gefunden wurde \autocite{sutton2018reinforcement}. Q-Learning trifft dabei Entscheidungen, ohne explizit Spielregeln oder Strategien vorzugeben. In einer Q-Tabelle werden alle möglichen Kombinationen an Zuständen und Entscheidungen mit der erhaltenen Belohnung gespeichert \autocite{TechnicalNoteQLearning1992}. Eine Solche Q-Tabelle benötigt enorme Speicherkapazität und schnelle Speicherzugriffe, die in gewählten System nicht zur Verfügung stehen. Das initiale Lernen der KI könnte auf einem anderen Rechner erfolgen, jedoch würde dies dennoch enorme Zeit in Anspruch nehmen. Für die Anwendung in Othello wäre hier der Nutzen nicht genug gegeben.

\paragraph{Multi Prob Cut}
\label{subsec:multi-prob-cut}
 ist eine Technik zur Reduzierung der Anzahl von Knoten in Spielbäumen, indem statistische Wahrscheinlichkeiten genutzt werden, um Knoten frühzeitig zu verwerfen. Dazu werden Daten von Knoten gleicher Tiefe und ähnlicher Struktur gesammelt. Anhand dieser gesammelten Daten schätzt der Algorithmus, ob ein Verwerfen des aktuellen Knoten wahrscheinlich ist. In Abhängigkeit dieser Wahrscheinlichkeit wird dies durchgeführt \autocite{jiang2003first}. Dies führt dazu, dass der Algorithmus weniger zuverlässig wird, wenn das Wahrscheinlichkeitsmodell ungenau ist. Auch hier wird wieder viel Speicher benötigt, um die historischen Daten zu hinterlegen, zusätzlich ist noch ein umfangreiches Feintunen der Wahrscheinlichkeiten nötig, um den Algorithmus zuverlässig zu machen.

\paragraph{A*-Suche}
\label{subsec:a-star-search}
 ist ein Suchalgorithmus mit primärem Fokus auf Pfadfindung und Graphen und weniger in der Spieltheorie aufzufinden. Er basiert auf dem Dijkstra-Algorithmus. Dieser dient dazu, den kürzesten Weg von einem Startknoten zu allen anderen Knoten in einem Graphen zu finden. Stark vereinfacht findet dieser durch das Besuchen aller Knoten und der Betrachtung dessen Nachbarknoten statt \autocite[S.~269-271]{dijkstra1959note}. Anwendungen hierfür sind häufig in Netzwerken oder Navigation. Da es in Othello hingegen keine Überschneidungen der Pfade gibt und ein theoretischer kürzester Weg zu einem Ende des Spiels nur von sehr geringer Relevanz ist, ist auch die Anwendung der A*-Suche mithilfe von Heuristiken, welche die Suche effizienter machen, nicht sinnvoll \autocite{4082128}.

\paragraph{Monte-Carlo-Tree-Search}
\label{subsec:mcts}
 bewertet Züge durch wiederholte, zufällige Simulationen des Spiels und aktualisiert die Knotenwerte entsprechend der erzielten Ergebnisse. Dazu wird zu Beginn ein Wurzelknoten ausgewählt, der vielversprechend erscheint. Darauf wird an jedem Knoten ein Kindknoten gewählt, der einen Zug repräsentiert. Ausgehend hiervor werden zufällig oder heuristisch Knoten bis zum Ende des Spiels ausgewählt. Das Ergebnis des Spiels ist im Falle von Othello ein Sieg, eine Niederlage oder ein Remis. Ausgehend von dem Ergebnis wird die Qualität des Zuges geschätzt. Für zukünftige Iterationen werden die Entscheidungen dann auf dieser Grundlage gewichtet. Ein Kernbestandteil der Monte-Carlo-Tree-Search ist das Prinzip von Upper Confidence Bounds applied to Tree Search. Das Prinzip dient dazu, anhand von der Balance zwischen Ausbeutung und Erkundung den besten Kindknoten zu ermitteln. Ausbeutung steht hierbei für bisher als positiv angesehene Knoten und Erkundung für wenig besuchte Knoten. Anhand der Formel \linebreak $\text{UCT}_i = \frac{w_i}{n_i} + c \sqrt{\frac{\ln N}{n_i}}$ wird die Attraktivität eines bestimmten Kindknotens errechnet. Dazu werden dessen bisheriger Erfolg $w_i$, die Anzahl der Besuche $n_i$, die Anzahl der Besuche des Elternknotens $N$ und die Gewichtung der Erkundung $c$ verwendet  \autocite{browne2012survey}. Ähnlich wie bei Multi Prob Cut wird hierfür viel Zeit benötigt, um eine optimale Simulationsstrategie zu erzielen, sowie viele Simulationen selbst, um stabile Ergebnisse zu erhalten.

% Referenzsatz: Auf Basis der spieltheoretischen Einordnung als deterministisches Zwei-Personen-Nullsummenspiel mit vollständiger Information kann Othello als adversarielles Suchproblem modelliert werden. Aufgrund der hohen Zustandsraumkomplexität sind klassische Minimax-basierte Verfahren nur in Verbindung mit Suchbaumreduktion, Tiefenbegrenzung und heuristischen Bewertungsfunktionen praktisch einsetzbar.